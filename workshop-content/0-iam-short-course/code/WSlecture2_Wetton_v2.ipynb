{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sc\n",
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "import pandas\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.linalg import spsolve\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with y = exp(x) + normal noise, $x \\in [0,1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 20\n",
    "h = 1./N\n",
    "noise = 0.1\n",
    "x = np.arange(N)*h\n",
    "yexact = np.exp(x)\n",
    "y = yexact+noise*np.random.normal(size=x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do linear regression using the lecture formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2sum = np.sum(x**2)\n",
    "xsum = np.sum(x)\n",
    "ysum = np.sum(y)\n",
    "xysum = np.sum(x*y)\n",
    "A = [[x2sum,xsum],[xsum,N]]\n",
    "b = [xysum, ysum]\n",
    "u = np.linalg.solve(A, b)\n",
    "mlin = u[0]\n",
    "blin = u[1]\n",
    "print 'm: %10.6f b: %10.6f' % (mlin,blin)\n",
    "yfit = mlin*x+blin\n",
    "plt.figure(1)\n",
    "plt.plot(x,yexact,x,y,'ro',x,yfit)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the numpy least squares routine, that probably does SVD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmatrix = np.zeros((N,2))\n",
    "xmatrix[:,0] = x\n",
    "xmatrix[:,1] = np.zeros(N)+1\n",
    "m, b = np.linalg.lstsq(xmatrix,y)[0]\n",
    "print 'm: %10.6f b: %10.6f' % (m,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do a quadratic fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmatrix = np.zeros((N,3))\n",
    "xmatrix[:,0] = x**2\n",
    "xmatrix[:,1] = x\n",
    "xmatrix[:,2] = np.zeros(N)+1\n",
    "q, l, b = np.linalg.lstsq(xmatrix,y)[0]\n",
    "print 'q: %10.6f l: %10.6f b: %10.6f' % (q,l,b)\n",
    "yfit = q*x**2+l*x+b\n",
    "plt.figure(1)\n",
    "plt.plot(x,yexact,x,y,'ro',x,yfit)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you were a statistician you would know what all this means..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope, intercept, r_value, p_value, std_err = stats.linregress(x,y)\n",
    "print 'm: %10.6f b: %10.6f' % (slope,intercept)\n",
    "print \"r-squared:\", r_value**2\n",
    "print 'p value:', p_value # two-sided p-value for a hypothesis test whose null hypothesis is that the slope is zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and this might need a graduate statistics degree... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pandas.DataFrame({'x2': x**2, 'x': x, 'y': y})\n",
    "\n",
    "# Fit the model\n",
    "model = ols(\"y ~ x2 + x\", data).fit()\n",
    "\n",
    "# Print the summary\n",
    "print(model.summary())\n",
    "\n",
    "# Fitted parameters\n",
    "print(\"\\nParameter estimates:\")\n",
    "print(model._results.params)\n",
    "\n",
    "# Peform analysis of variance on fitted linear model\n",
    "anova_results = anova_lm(model)\n",
    "print('\\nANOVA results')\n",
    "print(anova_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The effect of an outlier -- leads to an exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = y\n",
    "y2[N-1] = 5\n",
    "x2sum = np.sum(x**2)\n",
    "xsum = np.sum(x)\n",
    "ysum = np.sum(y2)\n",
    "xysum = np.sum(x*y2)\n",
    "A = [[x2sum,xsum],[xsum,N]]\n",
    "b = [xysum, ysum]\n",
    "u = np.linalg.solve(A, b)\n",
    "mlin = u[0]\n",
    "blin = u[1]\n",
    "print 'm: %10.6f b: %10.6f' % (mlin,blin)\n",
    "yfit = mlin*x+blin\n",
    "plt.figure(1)\n",
    "plt.plot(x,yexact,x,y2,'ro',x,yfit)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Nonlinear System Example\n",
    "\n",
    "The discretization of $-u^{\\prime \\prime}+u+u^3 = f$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 64;\n",
    "pi = math.pi\n",
    "h = 2*pi/N\n",
    "fact = 1/h**2\n",
    "A = csr_matrix((N,N))\n",
    "x = np.arange(N)*h\n",
    "rhs = np.zeros(N)\n",
    "for j in range(0,N):  \n",
    "    rhs[j] = math.exp(math.cos(x[j]))*(math.cos(x[j])+math.cos(x[j])**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "function to return the Jacobian matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Jacobian(A,u,fact,rhs):\n",
    "    vres = np.zeros(N)\n",
    "    for j in range(0,N):  # loop by matrix row\n",
    "        A[j,j] = 2*fact+1+3*u[j]**2 # diagonals\n",
    "        if j==0:\n",
    "            jm = N-1\n",
    "        else:\n",
    "            jm = j-1\n",
    "        if j==N-1:\n",
    "            jp = 0\n",
    "        else:\n",
    "            jp = j+1\n",
    "        A[j,[jp,jm]] = -fact # off diagonals\n",
    "        vres[j] = 2*fact*u[j] + u[j]**3 + u[j] - fact*(u[jm]+u[jp])-rhs[j]\n",
    "    return[A, vres]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Newton iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tol = 1e-6\n",
    "res = 2*tol \n",
    "count = 0 \n",
    "u = np.zeros(N)\n",
    "A,vres = Jacobian(A,u,fact,rhs)\n",
    "print 'Iteration count and max norm residual:'\n",
    "while res > tol and count < 8:\n",
    "    count = count +1\n",
    "    delta = spsolve(A, vres)\n",
    "    u = u - delta\n",
    "    A,vres = Jacobian(A,u,fact,rhs)\n",
    "    res = np.amax(np.absolute(vres))\n",
    "    print count, res\n",
    "plt.figure(1)\n",
    "plt.plot(x,u) \n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization Example\n",
    "\n",
    "Minimization of the Rosenbrock function\n",
    "\n",
    "Code taken directly from the scipy web pages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rosen(x):\n",
    "     return sum(100.0*(x[1:]-x[:-1]**2.0)**2.0 + (1-x[:-1])**2.0)\n",
    "    \n",
    "def rosen_der(x):\n",
    "     xm = x[1:-1]\n",
    "     xm_m1 = x[:-2]\n",
    "     xm_p1 = x[2:]\n",
    "     der = np.zeros_like(x)\n",
    "     der[1:-1] = 200*(xm-xm_m1**2) - 400*(xm_p1 - xm**2)*xm - 2*(1-xm)\n",
    "     der[0] = -400*x[0]*(x[1]-x[0]**2) - 2*(1-x[0])\n",
    "     der[-1] = 200*(x[-1]-x[-2]**2)\n",
    "     return der\n",
    "\n",
    "def rosen_hess(x):\n",
    "     x = np.asarray(x)\n",
    "     H = np.diag(-400*x[:-1],1) - np.diag(400*x[:-1],-1)\n",
    "     diagonal = np.zeros_like(x)\n",
    "     diagonal[0] = 1200*x[0]**2-400*x[1]+2\n",
    "     diagonal[-1] = 200\n",
    "     diagonal[1:-1] = 202 + 1200*x[1:-1]**2 - 400*x[2:]\n",
    "     H = H + np.diag(diagonal)\n",
    "     return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.array([1.3, 0.7, 0.8, 1.9, 1.2])\n",
    "res = minimize(rosen, x0, method='Newton-CG', jac=rosen_der, hess=rosen_hess, options={'xtol': 1e-8, 'disp': True})\n",
    "print res.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = minimize(rosen, x0, method='Newton-CG', jac=rosen_der, options={'xtol': 1e-8, 'disp': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = minimize(rosen, x0, method='BFGS', jac=rosen_der, options={'disp': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res = minimize(rosen, x0, method='BFGS', options={'disp': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = minimize(rosen, x0, method='nelder-mead', options={'xtol': 1e-8, 'disp': True})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
